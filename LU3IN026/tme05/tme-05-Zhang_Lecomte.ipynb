{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2024-2025\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME 5 : Validation croisée (fin), astuce du noyau, réduction de dimensionnalité: visualisation & débruitage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\"><b>[Q]</b></font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zhang Yuxiang & Lecomte Antoine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-05</tt> et rajouter à la suite de <tt>tme-05</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-05-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font>.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Version python et des librairies:\n",
      "\tPython  3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "\tpandas:  2.2.3\n",
      "\tnumpy:  2.2.2\n",
      "\tmatplotlib:  3.10.0\n"
     ]
    }
   ],
   "source": [
    "# - - - - - - - - - - - - - - - - - -\n",
    "# imports utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mtpl\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Les instructions suivantes sont utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - -\n",
    "# Information sur l'environnent utilisé ici:\n",
    "print(\"Version python et des librairies:\")\n",
    "print(\"\\tPython \",sys.version)\n",
    "print(\"\\tpandas: \",pd.__version__)\n",
    "print(\"\\tnumpy: \",np.__version__)\n",
    "print(\"\\tmatplotlib: \",mtpl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# importation de evaluation\n",
    "from iads import evaluation as ev\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilan des séances précédentes\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Avant de commencer ce sujet, vous devez avoir terminé les TME précédents:\n",
    "\n",
    "1. les fonctions pour générer des datasets uniformes, gaussiens et XOR.\n",
    "2. les classifieurs: ClassifierKNN, ClassifierLineaireRandom, ClassifierPerceptron, ClassifierPerceptronBiais\n",
    "3. le classifieur multiclasses ClassifierMultiOOA    \n",
    "4. les fonctions de validation croisée: crossval, crossval_strat et analyse_perfs\n",
    "5. toutes les fonctions et classes doivent avoir été testées et validées, et recopiées dans les fichiers correspondants:\n",
    "    - utils.py pour les fonctions 1) \n",
    "    - Classifiers.py pour les fonctions 2) et 3) \n",
    "    - evaluations.py pour les fonctions 4)\n",
    "\n",
    "Si vous n'avez pas terminé un de ces points, consacrez le début de ce TME 5 à vous mettre à jour.\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Une fonction pour la validation croisée\n",
    "\n",
    "Reprendre le code écrit dans le TME 4 pour évaluer par validation croisée le perceptron biais.\n",
    "\n",
    "**Remarque**: penser à créer un lien symbolique vers le sous-répertoire `data` (qui contient `usps.pkl`) dans le répertoire de ce TME 4 (cf. séances précédentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances avec les classes  2  et  6\n",
      "Analyse perf: moyenne: nan\tecart: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antoine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Antoine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Antoine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\Antoine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "C:\\Users\\Antoine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:215: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# test sur les données USPS\n",
    "import pickle as pkl\n",
    "\n",
    "data = pkl.load(open('data/usps.pkl', 'rb'))\n",
    "Xu = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Yu = np.array(data['Y_train'], dtype=float)\n",
    "\n",
    "# Création d'un sous groupe de données\n",
    "c1 = 2  # ---> sera associée au label +1  \n",
    "c2 = 6  # ---> sera associée au label -1\n",
    "X12 = Xu[(Yu==c1) | (Yu==c2)]\n",
    "Y12 = np.where(Yu[(Yu==c1) | (Yu==c2)]==c1, 1, -1)\n",
    "\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = X12.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "# Liste pour stocker les taux de bonne classification à chaque itération\n",
    "perf = []\n",
    "\n",
    "print(\"Performances avec les classes \", c1,\" et \", c2)\n",
    "# ######################## A COMPLETER CI-DESSOUS\n",
    "# 1) mélanger des exemples \n",
    "\n",
    "# 2) réaliser une validation croisée complète avec le perceptron biais\n",
    "\n",
    "\n",
    "# ######################## \n",
    "   \n",
    "taux_moyen, taux_ecart = ev.analyse_perfs(perf)\n",
    "print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\\tecart: {taux_ecart:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> À partir de maintenant, on évaluera souvent les classifieurs en utilisant une validation croisée, pour faciliter cela, écrire la fonction `validation_croisee` qui prend en argument un nom de classe de classifieur, un tuple composé d'un dataset et de son ensemble de labels, et un entier naturel donnant le nombre d'itérations à réaliser. Cette fonction rend un triplet contenant la liste des performances obtenues, la performance moyenne set l'écart type.\n",
    "\n",
    "Cette fonction doit réaliser le traitement que vous avez implémenté dans la boîte précédente et qui débute **après le mélange des exemples**, c'est-à-dire que cette fonction implémente l'étape 2) de la boîte précédente.\n",
    "\n",
    "\n",
    "<font color=\"RED\"><b>Attention !</b></font>: lors de la validation croisée, vous devrez dupliquer le classifieur afin qu'il soit ré-entrainé complètement depuis son état initial à chaque tour. Pour cela, vous utiliserez la commande `copy.deepcopy` qui permet d'obtenir une copie complète de l'objet classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  # pour deepcopy()\n",
    "\n",
    "def validation_croisee(C, DS, nb_iter):\n",
    "    \"\"\" Classifieur * tuple[array, array] * int -> tuple[ list[float], float, float]\n",
    "    \"\"\"\n",
    "    #############\n",
    "    # A COMPLETER\n",
    "    #############    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performances avec les classes  2  et  6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m cl \u001b[38;5;241m=\u001b[39m classif\u001b[38;5;241m.\u001b[39mClassifierPerceptronBiais(dim, eps, poids_0)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Remarque: ici, on ne mélange pas les exemples avant la validation croisée\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Evaluation du classifieur par validation croisée:\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m perf, taux_moyen, taux_ecart \u001b[38;5;241m=\u001b[39m validation_croisee(cl, (X12, Y12), nb_iter)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ######################## \u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalyse perf: moyenne: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtaux_moyen\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mecart: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtaux_ecart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = X12.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "\n",
    "print(\"Performances avec les classes \",c1,\" et \", c2)\n",
    "\n",
    "# Création du classifieur que l'on veut évaluer:\n",
    "cl = classif.ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "\n",
    "# Remarque: ici, on ne mélange pas les exemples avant la validation croisée\n",
    "\n",
    "# Evaluation du classifieur par validation croisée:\n",
    "perf, taux_moyen, taux_ecart = validation_croisee(cl, (X12, Y12), nb_iter)\n",
    "\n",
    "# ######################## \n",
    "print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\\tecart: {taux_ecart:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "À partir d'ici, on considére que votre fonction  `validation_croisee` est opérationnelle et qu'elle a été ajoutée dans le fichier `evaluation.py` de la librairie `iads`.\n",
    "\n",
    "</class>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appel de la fonction `validation_croisee` une fois mise dans la librairie `iads`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = X12.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "\n",
    "print(\"Performances avec les classes \",c1,\" et \", c2)\n",
    "\n",
    "# Création du classifieur que l'on veut évaluer:\n",
    "cl = classif.ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "\n",
    "# Remarque: ici, on ne mélange pas les exemples avant la validation croisée\n",
    "\n",
    "# Evaluation du classifieur par validation croisée:\n",
    "perf, taux_moyen, taux_ecart = ev.validation_croisee(cl, (X12, Y12), nb_iter)\n",
    "\n",
    "# ######################## \n",
    "print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\\tecart: {taux_ecart:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée sur un classifieur multi-classes\n",
    "\n",
    "\n",
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Tester le classifieur multiclasse du TME 4, basé sur un classifieur perceptron biais, avec l'ensemble des données usps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # pour chronométrer...\n",
    "\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = Xu.shape[1]   # la dimension est donnée par le nombre de colonnes de Xu\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 3\n",
    "\n",
    "print(\"Performances avec toutes les classes (ATTENTION: cela peut être long !)\")\n",
    "\n",
    "# ######################## A COMPLETER CI-DESSOUS\n",
    "# 1) créer le classifieur de base\n",
    "\n",
    "# 2) créér le classifieur multi-classes\n",
    "\n",
    "\n",
    "# ######################## \n",
    "\n",
    "# Remarque: ici, on ne mélange pas les exemples avant la validation croisée\n",
    "\n",
    "# Evaluation du classifieur par validation croisée:\n",
    "tic = time.time()  # On lance le chrono\n",
    "perf, taux_moyen, taux_ecart = ev.validation_croisee(cl, (Xu, Yu), nb_iter)\n",
    "toc = time.time()  # On arrête le chrono\n",
    "\n",
    "print(f'Temps passe: {(toc-tic):0.4f} secondes.')\n",
    "print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\\tecart: {taux_ecart:0.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retour sur le XOR\n",
    "\n",
    "Dans le TME 3, vous avez implémenté la fonction `create_XOR` qui permet de générer des données avec une distribution des classes très difficile à apprendre avec nos classifieurs linéaires.\n",
    "\n",
    "Par exemple, on peut générer 400 exemples répartis équitablement en 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retour sur le XOR avec la fonction du TME 3 (mise dans votre librairie)\n",
    "\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Génération d'un dataset avec 400 exemples (100 par région du XOR):\n",
    "data_xor, label_xor = ut.create_XOR(100,0.01)\n",
    "ut.plot2DSet(data_xor, label_xor)\n",
    "\n",
    "print(\"Nombre total d'exemples générés: \",data_xor.shape[0])\n",
    "print(\"Nombre d'exemples de classe +1: \",data_xor[label_xor==+1].shape[0])\n",
    "print(\"Nombre d'exemples de classe -1: \",data_xor[label_xor==-1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = data_xor.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "\n",
    "# Création du classifieur que l'on veut évaluer:\n",
    "cl = classif.ClassifierPerceptron(dim, eps, poids_0)\n",
    "\n",
    "# Remarque: on ne mélange pas les exemples avant la validation croisée car ils sont déjà dans un ordre aléatoire\n",
    "\n",
    "# Evaluation du classifieur par validation croisée:\n",
    "perf, taux_moyen, taux_ecart = ev.validation_croisee(cl, (data_xor, label_xor), nb_iter)\n",
    "\n",
    "# ######################## \n",
    "print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\\tecart: {taux_ecart:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats précédents ne sont vraiment pas très bons, le perceptron n'arrive pas à séparer correctement les 2 classes... (expliquer pourquoi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'asture du noyau (*Kernel Trick*)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Comme vu en cours, l'**astuce du noyau (\"kernel trick\")** est un moyen pour améliorer ses performances.\n",
    "\n",
    "Un **noyau** est une **fonction** (on parle de *fonction noyau*, *noyau* ou *kernel*) qui permet de représenter des données d'un espace donné dans un autre espace, souvent de dimension plus grande.\n",
    "\n",
    "Par exemple, on considère une matrice en 2D d'observations:\n",
    "$$X =\\left[\n",
    "    \\begin{array}{cc}\n",
    "    x_{11} & x_{12}\\\\\n",
    "    \\vdots & \\vdots \\\\\n",
    "    x_{N1} & x_{N2}\\\\\n",
    "    \\end{array}\n",
    "    \\right]\\in \\mathbb R^{N\\times 2}$$\n",
    "\n",
    "La fonction produite par un perceptron, $f(\\mathbf x) = \\mathbf w \\cdot \\mathbf x$, correspond à une frontière linéaire dans l'espace 2D... Qui passe par $(0,0)$.\n",
    "\n",
    "Mais supposons que nous ajoutons des colonnes à $X$:\n",
    "$$X^* =\\left[\n",
    "    \\begin{array}{cccccc}\n",
    "    x_{11} & x_{12} & x_{11}^2 & x_{12}^2 & x_{11} x_{12} & 1 \\\\\n",
    "    \\vdots & \\ddots &&&&\\vdots\\\\\n",
    "    x_{N1} & x{N2} & x_{N1}^2 & x_{N2}^2 & x_{N1} x_{N2} & 1 \\\\\n",
    "    \\end{array}\n",
    "    \\right]\\in \\mathbb R^{N\\times 6}$$\n",
    "\n",
    "Les colonnes ajoutées sont obtenues à partir des colonnes initiales de $X$.\n",
    "\n",
    "Maintenant, la fonction $f(\\mathbf x^*) = \\mathbf w \\cdot \\mathbf x^*$ correspond toujours à une frontière linéaire mais cette fois-ci dans un espace 6D... \n",
    "Mais sa projection dans l'espace 2D d'origine est une frontière non linéaire !\n",
    "\n",
    "\n",
    "Un **noyau**  est donc une fonction de transformation\n",
    "$$\\begin{array}{cccc}\n",
    "    K:& X & \\rightarrow & X^*\\\\\n",
    "      & \\mathbf x & \\mapsto &\\mathbf x^*\n",
    "\\end{array}$$\n",
    "\n",
    "</div>\n",
    "\n",
    "**Note** Il faudra être très attentif, on fait tous les calculs avec des $\\mathbf x^*$ mais on fait tous les affichages avec des $\\mathbf x$...\n",
    "\n",
    "Pour représenter des noyaux, on définit une classe abstraite `Kernel` qui sera étendue pour chaque noyau que l'on souhaitera créer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLasse (abstraite) pour représenter des noyaux\n",
    "class Kernel():\n",
    "    \"\"\" Classe pour représenter des fonctions noyau\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        \"\"\" Constructeur de Kernel\n",
    "            Argument:\n",
    "                - dim_in : dimension de l'espace de départ (entrée du noyau)\n",
    "                - dim_out: dimension de l'espace de d'arrivée (sortie du noyau)\n",
    "        \"\"\"\n",
    "        self.input_dim = dim_in\n",
    "        self.output_dim = dim_out\n",
    "        \n",
    "    def get_input_dim(self):\n",
    "        \"\"\" rend la dimension de l'espace de départ\n",
    "        \"\"\"\n",
    "        return self.input_dim\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        \"\"\" rend la dimension de l'espace d'arrivée\n",
    "        \"\"\"\n",
    "        return self.output_dim\n",
    "    \n",
    "    def transform(self, V):\n",
    "        \"\"\" ndarray -> ndarray\n",
    "            fonction pour transformer V dans le nouvel espace de représentation\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError(\"Please Implement this method\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'intérêt de définir une telle classe `Kernel` pour définir des noyaux est qu'elle permettra de définir des algorithmes de façon générique qui pourront alors prendre des noyaux quelconques en argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un premier noyau\n",
    "\n",
    "Le premier noyau, très simple, que l'on définit permet de projeter (manuellement) des données 2D dans un espace de plus grande dimension. \n",
    "\n",
    "Voici un exemple de projection qui transforme le vecteur $(x_1,x_2)$ en vecteur $(x_1,x_2,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelBias(Kernel):\n",
    "    \"\"\" Classe pour un noyau simple 2D -> 3D\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Constructeur de KernelBias\n",
    "            pas d'argument, les dimensions sont figées\n",
    "        \"\"\"\n",
    "        # Appel du constructeur de la classe mère\n",
    "        super().__init__(2,3)\n",
    "        \n",
    "    def transform(self, V):\n",
    "        \"\"\" ndarray de dim 2 -> ndarray de dim 3            \n",
    "            rajoute une 3e dimension au vecteur donné\n",
    "        \"\"\"\n",
    "        \n",
    "        if (V.ndim == 1): # on regarde si c'est un vecteur ou une matrice\n",
    "            W = np.array([V]) # conversion en matrice\n",
    "            V_proj = np.append(W,np.ones((len(W),1)),axis=1)\n",
    "            V_proj = V_proj[0]  # on rend quelque chose de la même dimension\n",
    "        else:\n",
    "            V_proj = np.append(V,np.ones((len(V),1)),axis=1)\n",
    "            \n",
    "        return V_proj\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation : \n",
    "kb = KernelBias()\n",
    "\n",
    "data_xor_bias= kb.transform(data_xor)\n",
    "\n",
    "data_xor_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un noyau un peu plus compliqué\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Définir la classe `KernelPoly` permettant de représenter le noyau : $(x_1,x_2) \\mapsto (1,x_1,x_2,x_1*x_1,x_2*x_2,x_1*x_2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "\n",
    "class KernelPoly(Kernel):\n",
    "    def __init__(self):\n",
    "        \"\"\" Constructeur de KernelPoly\n",
    "            pas d'argument, les dimensions sont figées\n",
    "        \"\"\"\n",
    "        # Appel du constructeur de la classe mère\n",
    "        super().__init__(2,6)\n",
    "        \n",
    "    def transform(self,V):\n",
    "        \"\"\" ndarray de dim 2 -> ndarray de dim 6            \n",
    "            ...\n",
    "        \"\"\"\n",
    "        ## TODO\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation \n",
    "\n",
    "kp = KernelPoly()\n",
    "\n",
    "data_xor_poly = kp.transform(data_xor[0:4])\n",
    "\n",
    "data_xor_poly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter la classe `ClassifierPerceptronKernel` qui étend la classe `Classifier`. \n",
    "Pour définir cette classe possède les mêmes fonctionnalités que celles de la classe `ClassifierPerceptron`, en plus, elle prend en argument, lors de sa construction, un noyau (instance de la classe `Kernel`).\n",
    "Une différence majeure avec le perceptron normal, et que le dataset fourni pour les méthodes `train_step` et `train`, ainsi que l'exemple donnée pour une prédiction, doit être *kernélisé* avant d'appliquer le traitement.\n",
    "\n",
    "*Remarques :*\n",
    "- le données sont donc kernélisée dans l'objet `ClassifierPerceptronKernel`.\n",
    "- toutes les méthodes de la classe `ClassifierPerceptronKernel` ne sont pas nécessairement à réécrire dans `ClassifierPerceptron`, seulement celles qui sont impactées par le changement apporté par l'utilisation du kernel..\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "class ClassifierPerceptronKernel(classif.ClassifierPerceptron):\n",
    "    \"\"\" Perceptron de Rosenblatt kernelisé\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dimension, learning_rate, noyau, init=0):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - input_dimension (int) : dimension de la description des exemples (espace originel)\n",
    "                - learning_rate : epsilon\n",
    "                - noyau : Kernel à utiliser\n",
    "                - init est le mode d'initialisation de w: \n",
    "                    - si 0 (par défaut): initialisation à 0 de w,\n",
    "                    - si 1 : initialisation par tirage aléatoire de valeurs petites\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "        \n",
    "    def train_step(self, desc_set, label_set):\n",
    "        \"\"\" Réalise une unique itération sur tous les exemples du dataset\n",
    "            donné en prenant les exemples aléatoirement.\n",
    "            Arguments: (dans l'espace originel)\n",
    "                - desc_set: ndarray avec des descriptions\n",
    "                - label_set: ndarray avec les labels correspondants\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "     \n",
    "    def score(self,x):\n",
    "        \"\"\" rend le score de prédiction sur x \n",
    "            x: une description (dans l'espace originel)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Entraîner un perceptron kernelisé utilisant un `KernelPoly` sur un dataset correspondant au XOR. Que constate-t-on ? Expliquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour avoir les mêmes valeurs aléatoires :\n",
    "np.random.seed(42)   # supprimer cette ligne une fois la mise au point terminée\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = data_xor.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# <------------------------ A COMPLETER  ------------------------------>\n",
    "\n",
    "\n",
    "# Pour mémoriser les différence:\n",
    "les_variations = perceptron_kernel.train(data_xor, label_xor)\n",
    "print(\"Nb iterations: \",len(les_variations))\n",
    "\n",
    "# Affichage de la frontière de séparation des classes\n",
    "# <------------------------ A COMPLETER  ------------------------------>\n",
    "\n",
    "\n",
    "print(\"Accuracy finale : \", perceptron_kernel.accuracy(data_xor, label_xor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut évaluer les résultats d'une validation croisée avec ce kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = data_xor.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "\n",
    "# Création du classifieur que l'on veut évaluer:\n",
    "cl = ClassifierPerceptronKernel(dim,eps,kernp,poids_0)\n",
    "\n",
    "# Remarque: on ne mélange pas les exemples avant la validation croisée car ils sont déjà dans un ordre aléatoire\n",
    "\n",
    "# Evaluation du classifieur par validation croisée:\n",
    "perf, taux_moyen, taux_ecart = ev.validation_croisee(cl, (data_xor, label_xor), nb_iter)\n",
    "\n",
    "# ######################## \n",
    "print(f'Analyse perf: moyenne: {taux_moyen:0.4f}\\tecart: {taux_ecart:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation de données\n",
    "\n",
    "Nous proposons une série d'expériences pour appréhender la visualisation de données et la réduction de la dimensionnalité:\n",
    "\n",
    "1. Comprendre la signification des valeurs propres et vecteurs propres sur les données gaussiennes sur lesquelles nous avons travaillé jusqu'ici\n",
    "1. Générer un jeu de données jouet en 3D puis réduire la dimensionnalité\n",
    "1. Appliquer cette réduction de dimension sur les données USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation:\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# générer des données gaussienne 2D\n",
    "\n",
    "N = 100\n",
    "X,Y =  ut.genere_dataset_gaussian([-1,-1],[[1,0],[0,1]], [1, 1],[[1,0],[0,1]],N)\n",
    "\n",
    "ut.plot2DSet(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Avant de poursuivre, répondez aux questions suivantes:\n",
    "- Combien y a-t-il de vecteurs propres et de valeurs propres dans ce problème?\n",
    "- Quel axe de plus forte variance est pressenti?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponses:\n",
    "\n",
    "\n",
    "[Entrez votre réponse ici]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Refaire les calculs précédents à la main, sur une feuille !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donner les instructions pour récupérer les valeurs propres et vecteurs propres de la \n",
    "# matrice X générée précédeemment, puis les afficher:\n",
    "\n",
    "\n",
    "# Décommentez et compléter la ligne suivante: \n",
    "\n",
    "# lam, V = np.linalg.eig( ########### COMPLETER ICI ############ ) \n",
    "\n",
    "\n",
    "\n",
    "# ###################################\n",
    "\n",
    "print(\"1er valeur rendue:\\n\", lam)\n",
    "print(\"2e valeur rendue :\\n\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracer les vecteurs propres, à partir de (0,0) sur le scatter des points (X,Y)\n",
    "# A l'aide de la commande plt.text, vous pouvez rajouter la \"force\" des axes si vous voulez\n",
    "\n",
    "plt.figure()\n",
    "plt.grid('on')\n",
    "# Affichage de l'ensemble des exemples :\n",
    "plt.scatter(X[Y==-1,0],X[Y==-1,1],marker='o', color=\"red\") # 'o' rouge pour la classe -1\n",
    "plt.scatter(X[Y==1,0],X[Y==1,1],marker='x', color=\"blue\") # 'x' bleu pour la classe +1\n",
    "# A COMPLETER \n",
    "\n",
    "# ###################################\n",
    "\n",
    "# Décommenter la ligne suivante pour avoir la légende :\n",
    "#plt.legend([\"cl1\", \"cl2\",\"axe 1\"+str(V[:,0]),\"axe 2\"+str(V[:,1])])\n",
    "\n",
    "\n",
    "# Si vous voulez sauvegarder l'image : \n",
    "#plt.savefig(\"out/acp.png\",bbox_inches='tight', transparent=True,pad_inches=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit bien la principale direction de variance (associée à la plus grande valeur propre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction de données 2D => 1D\n",
    "\n",
    "Dans une logique de réduction de dimensionnalité, on souhaite:\n",
    "1. extraire automatiquement le vecteur propre associé à la plus grande valeur propre\n",
    "1. projeter les données sur cet axe\n",
    "1. afficher le plot 1D des données suivant:\n",
    "    - x = nouvelle coordonée (unique) du point\n",
    "    - y = étiquette\n",
    "\n",
    "Cet affichage va nous permettre de comprendre ce que nous venons de faire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Donner les instructions qui réalisent les 3 étapes données ci-dessus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# A COMPLETER \n",
    "\n",
    "\n",
    "# ###################################\n",
    "plt.grid()\n",
    "\n",
    "#plt.savefig(\"out/proj_1D.png\",bbox_inches='tight', transparent=True,pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez obtenir:\n",
    "\n",
    "(si l'image ne s'affiche pas, aller la voir dans le répertoire `ressources/`, c'est l'image `proj_1D.png`.\n",
    "\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td><img src=\"ressources/proj_1D.png\" width=300px></td>\n",
    "    <td>L'axe de plus forte variance semble bien intéressant pour distinguer les deux classes de données</td>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "Pour mieux comprendre ce qui se passe, je vous propose la figure explicative suivante qui illustre ce que vous avez fait du point de vue géométrique:\n",
    "<img src=\"ressources/proj_2D.png\" width=300px>\n",
    "\n",
    "\n",
    "(si l'image ne s'affiche pas, aller la voir dans le répertoire `ressources/`, c'est l'image `proj_2D.png`.\n",
    "\n",
    "**Note:** cette dernière figure est non-triviale à obtenir, il ne faut pas perdre du temps en TP à chercher comment faire :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction de données d-D => 2D\n",
    "\n",
    "Passons maintenant sur les données USPS pour essayer de reproduire les figures du cours 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de pickle pour récupérer les données\n",
    "import pickle as pkl\n",
    "\n",
    "# Chargement des données USPS :\n",
    "\n",
    "# **** IMPORTANT ****\n",
    "# faire un lien vers le fichier usps.pkl qui a été fournie dans les TME précédents (répertoire ressources)\n",
    "# dans un sous-répertoire ressources du répertoire où se trouve ce notebook.\n",
    "# Ou bien : modifier dans open() pour mettre le bon chemin d'accès vers usps.pkl sur votre compte.\n",
    "\n",
    "data = pkl.load(open('data/usps.pkl', 'rb'))\n",
    "Xu = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Yu = np.array(data['Y_train'], dtype=float)\n",
    "XTu = np.array(data['X_test'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "YTu = np.array(data['Y_test'], dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Donner les instructions qui réalisent les 3 étapes suivantes:\n",
    "\n",
    "1. Extraire automatiquement les 2 vecteurs propres associés aux 2 plus grandes valeurs propres sur les données USPS\n",
    "1. Projeter les données sur ces axes\n",
    "    - projeter toutes les données\n",
    "    - projeter seulement les 200 premières images (pour mieux voir)\n",
    "1. Afficher avec un code couleur correspondant aux classes\n",
    "\n",
    "Cet affichage va nous permettre de comprendre ce que nous venons de faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A réaliser :\n",
    "\n",
    "# 1) calcul des vecteurs propres\n",
    "\n",
    "\n",
    "# 2) affichage (print)\n",
    "\n",
    "\n",
    "# 3) tri et sélection des 2 vecteurs associés aux 2 plus grandes valeurs propres \n",
    "\n",
    "\n",
    "# 4) affichage (plot) avec un code couleur pour les classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ####################################\n",
    "plt.legend(np.arange(10))\n",
    "#plt.show()\n",
    "\n",
    "#plt.savefig(\"out/proj_usps_all.png\",bbox_inches='tight', transparent=True,pad_inches=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez obtenir:\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td><img src=\"ressources/proj_usps_all.png\"></td>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "(si l'image ne s'affiche pas, aller la voir dans le répertoire `ressources/`, c'est l'image `proj_usps_all.png`.\n",
    "\n",
    "On a l'impression que les 0 et 1 sont bien séparés des autres classes... Le reste est un peu confus mais on voit que:\n",
    "- les 8 et les 9 se ressemblent\n",
    "- les 6 et les 3 dans une moindre mesure\n",
    "- les 7 et les 4 un peu aussi\n",
    "- les 2 sont en plein milieu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des vecteurs propres\n",
    "\n",
    "Chacun de nos 2 axes contient beaucoup d'informations... Mais lesquelles?\n",
    "Ces axes sont en 256 dimensions, il est possible de les tracer comme une image. L'idée est de distinguer les dimensions positives et les dimensions négatives.\n",
    "On ne va pas reconstruire une échelle de couleur propre... Mais on peut a minima afficher l'échelle.\n",
    "\n",
    "Le code est fourni ci-dessous.\n",
    "\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td><img src=\"ressources/vp_0.png\"></td>\n",
    "    <td><img src=\"ressources/vp_1.png\"></td>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "Le premier axe est sensible aux pixels allumés en haut et en bas: sur le premier axe de la figure de la boite précédente, on remarque que les chiffres les plus à droite sont le 0 et le 3... Ca colle.\n",
    "\n",
    "Le second axe est sensible aux pixels à gauche et à droite (en positif) et aux pixels du centre (en négatif). On a bien les 0 en haut et les 1 en bas de ce second axe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(vp.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.imshow(vp[:,i].reshape(16,16),cmap='bwr')\n",
    "    plt.colorbar()\n",
    "    #plt.savefig(\"out/vp_\"+str(i)+\".png\",bbox_inches='tight', transparent=True,pad_inches=0)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vers un espace de représentation débruité\n",
    "\n",
    "Que se passe-t-il si on classe les points dans cet espace?\n",
    "En 2d, on voit qu'il n'y a pas assez de dimension... Mais on peut:\n",
    "\n",
    "1. Etudier les valeurs de toutes les valeurs propres (triées) pour voir combien sont importantes\n",
    "    - soit on trie et on affiche les valeurs\n",
    "    - soit on trace un histogramme des valeurs\n",
    "1. Choisir un nombre de vecteurs propres par rapport à l'expérience précédente... On se rend compte que ce n'est pas évident: peu de valeurs propres captent toute l'énergie. En tout état de cause, 20 valeurs propres semblent raisonnables\n",
    "1. Projeter les données d'apprentissage et de test\n",
    "1. Etudier le taux de bonne classification dans ce nouvel espace par rapport à l'espace d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etude des valeurs propres\n",
    "plt.figure()\n",
    "\n",
    "# Regarder les 2 types d'affichage en commentant/décommentant l'un après l'autre:\n",
    "\n",
    "# Affichage d'un histogramme: (Essayez différentes tailles d'histrogramme)\n",
    "#plt.hist(lam, 20)\n",
    "\n",
    "# Affichage des valeurs :\n",
    "plt.plot(lam)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réduction à 20 dimensions\n",
    "ndim = 20\n",
    "Xr = Xu @ V[:,:ndim]\n",
    "XTr = XTu @ V[:,:ndim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time    # pour évaluer les temps d'exécution\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Apprentissage d'un perceptron multiclasses\n",
    "\n",
    "cl_reduit = classif.ClassifierPerceptron(ndim, 1e-3)\n",
    "clmulti_reduit = classif.ClassifierMultiOAA(cl_reduit)\n",
    "\n",
    "tic = time.time()  # On lance le chrono\n",
    "clmulti_reduit.train(Xr, Yu)\n",
    "toc = time.time()  # On arrête le chrono\n",
    "\n",
    "perf_A = clmulti_reduit.accuracy(Xr, Yu)\n",
    "perf_T = clmulti_reduit.accuracy(XTr, YTu)\n",
    "\n",
    "print(f\"Perfs : {perf_A:.4}, {perf_T:.4}, en {toc-tic:0.4} secondes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
